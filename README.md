# CS492_MLNLP_project
* Hierarchical Attention Networks for Document Classification 논문의 오픈소스를 가져와 customize & 여러가지 실험 수행
* Transformer에 쓰이는 Encoder나 Multihead attention을 사용하여 performance 향상 실험
* 기존 Baseline 모델과 큰 차이는 없음. 가장 성능이 좋았던 Multihead attention을 적용한 것이 현재 repository
